{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eVVaB-p6f12"
      },
      "source": [
        "# Word Inflection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "skmJSkBq6f15"
      },
      "source": [
        "## Data\n",
        "\n",
        "source: [github repository](https://github.com/sigmorphon/conll2017) - datasets for the 2017 joint CoNLL-SIGMORPHON shared task on morphological reinflection. The repository contains word inflection datasets for 52 languages. This project takes only three of the languages: English, Finnish and Spanish.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73R6TqQf63L5",
        "outputId": "4072c8c8-3e83-442d-f692-b3d96492e9cc"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Cm1aV9RK6f15"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os.path\n",
        "\n",
        "CONLL_SIGMORPHON_DATA_PATH=\"./data/conll2017\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2NhPd_wB6f17"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E8NiaUkO6f17"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def read_tsv(language, setting):\n",
        "    train = pd.read_csv(f\"{CONLL_SIGMORPHON_DATA_PATH}/all/task1/{language}-train-{setting}\",\n",
        "                        sep=\"\\t\", header=None, names=[\"input\",\"output\",\"msd\"])\n",
        "    dev = pd.read_csv(f\"{CONLL_SIGMORPHON_DATA_PATH}/all/task1/{language}-dev\",\n",
        "                        sep=\"\\t\", header=None, names=[\"input\",\"output\",\"msd\"])\n",
        "    test = pd.read_csv(f\"{CONLL_SIGMORPHON_DATA_PATH}/answers/task1/{language}-uncovered-test\",\n",
        "                        sep=\"\\t\", header=None, names=[\"input\",\"output\",\"msd\"])\n",
        "    return train, dev, test"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gP5GCbxO6f18"
      },
      "source": [
        "Both take a dataset as argument and `yield` lists as output. \n",
        "\n",
        "1. `yield_input()` `yields` lists of the form `[\"<start>\", \"w\", \"a\", \"l\", \"k\", \"FEAT=V\", \"FEAT=PAST\", \"<end>\"]`\n",
        "1. `yield_output()` `yields` lists of the form `[\"<start>\", \"w\", \"a\", \"l\", \"k\", \"e\", \"d\", \"<end>\"]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l-V8YARwFc0c",
        "outputId": "f8674c64-794b-4a54-ba8c-fb9090e23cd9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>output</th>\n",
              "      <th>msd</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>manducar</td>\n",
              "      <td>manducado</td>\n",
              "      <td>V.PTCP;PST;MASC;SG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>reestrenar</td>\n",
              "      <td>reestrenaba</td>\n",
              "      <td>V;IND;PST;3;SG;IPFV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fragmentar</td>\n",
              "      <td>fragmentaríamos</td>\n",
              "      <td>V;COND;1;PL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>descomponer</td>\n",
              "      <td>no descompongáis</td>\n",
              "      <td>V;NEG;IMP;2;PL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>fusilar</td>\n",
              "      <td>fusilas</td>\n",
              "      <td>V;IND;PRS;2;SG</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         input            output                  msd\n",
              "0     manducar         manducado   V.PTCP;PST;MASC;SG\n",
              "1   reestrenar       reestrenaba  V;IND;PST;3;SG;IPFV\n",
              "2   fragmentar   fragmentaríamos          V;COND;1;PL\n",
              "3  descomponer  no descompongáis       V;NEG;IMP;2;PL\n",
              "4      fusilar           fusilas       V;IND;PRS;2;SG"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df, _, _ = read_tsv(\"spanish\", \"medium\")\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "RKv4EMc36f18"
      },
      "outputs": [],
      "source": [
        "def yield_input(data):\n",
        "    for ex in data:\n",
        "        yield [\"<start>\"] + list(ex[0]) + [\"FEAT=\" + i for i in ex[2].split(\";\")] + [\"<end>\"]\n",
        "    \n",
        "def yield_output(data):\n",
        "    for ex in data:\n",
        "        yield [\"<start>\"] + list(ex[1]) + [\"<end>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NdhUwGzd6f19"
      },
      "outputs": [],
      "source": [
        "from collections import namedtuple\n",
        "from itertools import chain \n",
        "Example = namedtuple(\"Example\",[\"input\", \"output\"])\n",
        "\n",
        "class UDDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "        self.iloc = data.iloc\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.iloc[index]   \n",
        "    \n",
        "def read_data(language,setting,batch_size):\n",
        "    train_df, dev_df, test_df = read_tsv(language,setting)\n",
        "\n",
        "    train = UDDataset(train_df)\n",
        "    dev = UDDataset(dev_df)\n",
        "    test = UDDataset(test_df)\n",
        "\n",
        "    vocab = build_vocab_from_iterator(chain(yield_input(train), yield_output(train)),\n",
        "                                      specials=[\"<pad>\", \"<unk>\", \"<start>\", \"<end>\"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "    input_transform = lambda w: [vocab[c] for c in w]\n",
        "    output_transform = lambda w: [vocab[c] for c in w]\n",
        "    \n",
        "    def collate_batch(batch):\n",
        "        input_list, output_list, input_lens, output_lens = [], [], [], []\n",
        "        for lemma, wf, in zip(yield_input(batch), \n",
        "                              yield_output(batch)):\n",
        "            input_tensor = torch.tensor(input_transform(lemma), dtype=torch.long)\n",
        "            output_tensor = torch.tensor(output_transform(wf), dtype=torch.long)\n",
        "            input_list.append(input_tensor)\n",
        "            output_list.append(output_tensor)\n",
        "            input_lens.append(input_tensor.size()[0])\n",
        "            output_lens.append(output_tensor.size()[0])\n",
        "\n",
        "        return Example((pad_sequence(input_list, \n",
        "                                 batch_first=False, \n",
        "                                 padding_value=vocab[\"<pad>\"]), torch.tensor(input_lens, dtype=torch.long)),\n",
        "                       (pad_sequence(output_list, \n",
        "                                 batch_first=False, \n",
        "                                 padding_value=vocab[\"<pad>\"]), torch.tensor(output_lens, dtype=torch.long)))\n",
        "\n",
        "    train_iter = DataLoader(train, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
        "    dev_iter = DataLoader(dev, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
        "    test_iter = DataLoader(test, batch_size=1, shuffle=False, collate_fn=collate_batch)\n",
        "    \n",
        "    return train_iter, dev_iter, test_iter, vocab"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CBdS_8Ot6f19"
      },
      "source": [
        "Read the Spanish inflection dataset and print a training example returned by read_data along with the vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu22_OrG6f19",
        "outputId": "9a20b59b-b0f8-4c5e-e9bf-a2b7ded4b064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example(input=(tensor([[ 2],\n",
            "        [16],\n",
            "        [ 6],\n",
            "        [ 8],\n",
            "        [ 6],\n",
            "        [ 5],\n",
            "        [13],\n",
            "        [ 7],\n",
            "        [32],\n",
            "        [ 4],\n",
            "        [ 5],\n",
            "        [11],\n",
            "        [22],\n",
            "        [21],\n",
            "        [26],\n",
            "        [17],\n",
            "        [39],\n",
            "        [ 3]]), tensor([18])), output=(tensor([[ 2],\n",
            "        [16],\n",
            "        [ 6],\n",
            "        [ 8],\n",
            "        [ 6],\n",
            "        [ 5],\n",
            "        [13],\n",
            "        [ 7],\n",
            "        [32],\n",
            "        [ 4],\n",
            "        [14],\n",
            "        [10],\n",
            "        [ 8],\n",
            "        [ 3]]), tensor([14])))\n",
            "{'g': 28, 'FEAT=V': 11, '<pad>': 0, '<unk>': 1, 'r': 5, 'FEAT=3': 27, '<start>': 2, '<end>': 3, 'i': 7, 'FEAT=MASC': 52, 'FEAT=FEM': 50, 'a': 4, 'FEAT=PL': 17, 'e': 6, 'FEAT=NEG': 46, 's': 8, 'n': 9, 'FEAT=POS': 42, 'o': 10, 'c': 12, 't': 13, 'm': 14, 'l': 15, 'd': 16, 'u': 18, 'FEAT=SG': 19, 'FEAT=V.PTCP': 47, 'p': 20, 'FEAT=PST': 21, 'j': 41, 'FEAT=IND': 22, 'FEAT=LGSPEC1': 43, 'b': 23, 'FEAT=SBJV': 24, 'FEAT=2': 25, 'FEAT=1': 26, 'v': 29, 'f': 30, 'FEAT=PRS': 31, 'FEAT=IPFV': 40, 'z': 32, 'FEAT=NFIN': 54, 'h': 35, 'FEAT=FUT': 33, 'ü': 58, 'FEAT=IMP': 34, ' ': 36, 'á': 37, 'í': 38, 'ú': 57, 'FEAT=PFV': 39, 'é': 44, 'FEAT=COND': 45, 'q': 48, 'x': 49, 'ñ': 51, 'y': 53, 'ó': 55, 'FEAT=V.CVB': 56}\n"
          ]
        }
      ],
      "source": [
        "train_iter, dev_iter, test_iter, vocab = read_data(\"spanish\", \"medium\", 1)\n",
        "\n",
        "# Print the first training exaple\n",
        "example = next(iter(train_iter))\n",
        "print(example)\n",
        "print(vocab.get_stoi())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "FWNpi84q6f1-"
      },
      "source": [
        "### Basic Encoder-Decoder Model(without attention)\n",
        "\n",
        "EX: \n",
        "\n",
        "`<start> s t o d g e FEAT=V FEAT=PST <end>` into a single hidden state vector which is then fed into a decoder network\n",
        "\n",
        "Decoder then generates the output word form (`s t o d g e d`) one symbol at a time. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9LEwsjvT6f1-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.nn.functional import log_softmax\n",
        "from torch.optim import Adam, SGD\n",
        "\n",
        "from random import random, seed, shuffle\n",
        "\n",
        "# Ensure reproducible results.\n",
        "seed(0)\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "import re\n",
        "\n",
        "# Hyperparameters\n",
        "EMBEDDING_DIM=50\n",
        "RNN_HIDDEN_DIM=50\n",
        "RNN_LAYERS=1\n",
        "BATCH_SIZE=10\n",
        "CHAR_DROPOUT=0.0\n",
        "EPOCHS=10\n",
        "\n",
        "# Maximum length of generated output word forms.\n",
        "MAXWFLEN=40\n",
        "\n",
        "def accuracy(sys,gold):\n",
        "    assert(len(sys) == len(gold))\n",
        "    return sum([1 if x==y else 0 for x,y in zip(sys,gold)])*100.0/len(gold)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GUFrMQbr6f1-"
      },
      "source": [
        "#### Encoder Network\n",
        "\n",
        "\n",
        "`Encoder` class which serves as a wrapper for a character embedding and a bidirectional LSTM network. \n",
        "\n",
        "\n",
        "<!-- 1. Embed input sequence in `ex.input` using the character `self.embedding`. Given an input tensor of dimension `(sequence_length,1)`, this should result in a `(sequence_length,1,EMBEDDING_DIM)` tensor.\n",
        "1. Process the embedded input sequence using `self.rnn`. You should return the final hidden state returned by `self.rnn`. Note that `self.rnn` will return a hidden state of size `(2,1,RNN_HIDDEN_DIM)`.\n",
        "1. Your last task is to convert the hidden state returned by `self.rnn` into a `(1,1,2*RNN_HIDDEN_DIM)` tensor and return it. You can do this using several pytorch functions, for example `torch.cat` or `torch.view`. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FazpVDGk6f1_"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "        def __init__(self,alphabet):\n",
        "                super(Encoder,self).__init__()\n",
        "                self.embedding = nn.Embedding(len(alphabet), EMBEDDING_DIM)\n",
        "                self.rnn = nn.LSTM(EMBEDDING_DIM, RNN_HIDDEN_DIM, RNN_LAYERS, bidirectional=True)\n",
        "\n",
        "        def forward(self,ex):\n",
        "            input, _ = ex.input #(sequence_len, 1)\n",
        "            input = self.embedding(input) # (sequence_len, 1, embedding_dim)\n",
        "            hss, (hn, cn) = self.rnn(input) # hn: (2, 1, rnn_hidden_dim)\n",
        "            hs = torch.cat([hn[0], hn[1]], dim=1).unsqueeze(0) # (1,1, 2*rnn_hidden_dim)\n",
        "            return hs\n",
        "\n",
        "# An assertion to test that your implementation returns a tensor of the correct size. \n",
        "assert(Encoder(vocab.get_stoi())(example).size() == torch.Size([1,1,2*RNN_HIDDEN_DIM]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lDV-GpqJ6f1_"
      },
      "source": [
        "#### Decoder Network\n",
        "\n",
        "\n",
        "The `Decoder` class serves as a wrapper for a character embedding `embedding` and an LSTM network `rnn`. At each time-step `t`, the decoder `rnn` consumes an input vector which is a concatenation of an encoder hidden state and the embedding of the output character at position `t-1` in the output sequence (at position `t == 0`, this will be the embedding of the start of sequence symbol `<start>`). \n",
        "\n",
        "\n",
        "\n",
        "##### `Decoder.forward`\n",
        "\n",
        "The `forward` function is used when training the decoder. It takes an encoder hidden state `encoder_hs` corresponding to an input sequence like `<start> s t o d g e FEAT=V FEAT=PST <END>` and returns a tensor corresponding to the output sequence `s t o d g e d <END>`. However, the `forward` function does not directly return the output sequence. Instead, it returns a tensor `distr` of size `(output_length,1,alphabet_size)`. For example, `distr[6,0,15]` indicates the log-probability that the output symbol at position `t` will be symbol number `15` (imagine for example that `15 == self.alphabet[\"d\"]`).\n",
        "\n",
        "Since our decoder is trained using teacher forcing, we will feed in the gold standard output symbol at position `t-1` when predicting the output at position `t` in `forward`. You can access the gold standard output sequence via `ex.output`.\n",
        "\n",
        "In order to implement `forward`, you should:\n",
        "\n",
        "1. Embed the gold standard outputword form in `ex.output` using `self.embedding`. This should give you a tensor `embedded_output` of size `(output_length - 1,1,EMBEDDING_DIM)` (note the `- 1` which is a result of clipping the final `<end>` symbol form the output sequence `<start> s t o d g e d <end>`).\n",
        "1. Concatenate one copy of `encoder_hs` to each embedding vector in `embedded_output`. This should give you a tensor `decoder_input` of size `(output_length-1,1,EMBEDDING_DIM+2*RNN_HIDDEN_DIM)`.\n",
        "1. Run `self.rnn` on `decoder_output`. This should give you a tensor of hidden states `decoder_hidden_states` having  dimension `(output_length-1,1,RNN_HIDDEN_DIM)`.\n",
        "1. Apply `self.hidden2tag` and a `log_softmax` layer to `decoder_hidden_states`. this should give you a distribution tensor `distr` having dimension `(output_length-1,1,alphabet_size)`. \n",
        "1. Return `distr` and `output[1:]`.\n",
        "\n",
        "##### `Decoder.generate`\n",
        "\n",
        "The second function you need to implement is `generate`. It recursively generates an output word form given an encoder hidden state.  \n",
        "\n",
        "It takes only one argument: an encoder hidden state of dimension `(1,1,2*RNN_HIDDEN_STATE)`. In contrast to `forward`, you don't get a gold standard output sequence as parameter since we need to use `generate` during test time. Instead, it is your task to recursively generate the output sequence starting with the sequence inital symbol `\"<start>\"`. \n",
        "\n",
        "At each time step, you should feed the current output symbol `output_char` and the encoder hidden state `encoder_hs` as input to the decoder. It is your task to maintain the internal state `decoder_state`. It is a pair `(hs,cs)`, where `hs` is the decoder hidden state and `cs` is its cell state. You need to initialize the decoder to this state and update it using the return value of `self.rnn.forward`. You should then predict the next output symbol using the updated value of `decoder_state` and `self.hidden2char` echoing the `forward` function you just implemented.\n",
        "\n",
        "The `generate` function always produces an output of length `MAXWFLEN` but since this output may contain the `\"<end>\"` symbol, we can in reality generate shorter output sequences because `a b c <end> <end> ...` corresponds to the output word form `a b c`.\n",
        "\n",
        "In order to implement `generate`, you should:\n",
        "\n",
        "1. Embed `output_char` using `self.embedding`. This should give you a tensor `output_embedding` of dimension `(1,1,EMBEDDING_DIM)`.\n",
        "1. Run `self.rnn` on the concatenation of `output_embedding` and `encoder_hs`. Note that you need to initialize the decoder to `decoder_state`. You should use the return value to update `decoder_state`.\n",
        "1. Use the decoder hidden state `hs` from `decoder_state` and self.hidden2char to predict the next output character. You will probably need to use torch.argmax to find the most probable output symbol.\n",
        "1. Update the value of the `output_char` variable to the current output character and add it to the result array. Note that if `output_char == torch.Tensor([[1]])`, then you need to add the integer `1` to result. \n",
        "1. After `MAXWFLEN` time-steps, return `result`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW3ZRPVG2msT",
        "outputId": "1c3dfe20-b3d3-48a4-ba86-a82eef3d018e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.LongTensor([[vocab.get_stoi()[\"<start>\"]]])\n",
        "x.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zx3wx8f8QlI",
        "outputId": "fc8810f8-3485-48c3-af57-2cf8fd3e4b1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab.get_stoi()[\"<start>\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3dl1g7kH6f1_"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, alphabet):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.alphabet = alphabet\n",
        "        self.embedding = nn.Embedding(len(alphabet), EMBEDDING_DIM)\n",
        "        self.rnn = nn.LSTM(EMBEDDING_DIM+2*RNN_HIDDEN_DIM, RNN_HIDDEN_DIM, RNN_LAYERS, bidirectional=False)\n",
        "        self.hidden2char = nn.Linear(RNN_HIDDEN_DIM, len(alphabet))\n",
        "        \n",
        "    def forward(self,ex,encoder_hs):\n",
        "        # encoder_hs : (1,1, 2*rnn_hidden_dim)\n",
        "        output, output_length = ex.output # output: (seq_len, 1)  output is the golden label\n",
        "        output_em = self.embedding(output[:-1,:]) # (seq_length - 1,1,EMBEDDING_DIM)\n",
        "        # concat with input rep\n",
        "        encoder_hs_copy = encoder_hs.expand(output_em.size()[0], 1, 2*RNN_HIDDEN_DIM)\n",
        "        emb = torch.cat([output_em, encoder_hs_copy], dim=2) # (seq_length-1, 1, embedding_dim + 2*rnn_hidden_dim)\n",
        "        hss, _ = self.rnn(emb) # hss: (seq_length-1 x 1 x rnn_hidden_dim)\n",
        "        dist = self.hidden2char(hss) # (seq_length-1 x 1 x len(vocab))\n",
        "        dist = dist.log_softmax(dim = 2) # # (seq_length-1 x 1 x alphabet_size)\n",
        "        return dist, output[1:]\n",
        "\n",
        "\n",
        "        \n",
        "    def generate(self,encoder_hs):\n",
        "        # encoder_hs : (1,1, 2*rnn_hidden_dim)\n",
        "        # We're not accumulating gradients during test time.\n",
        "        with torch.no_grad():\n",
        "            decoder_state = (torch.zeros(1,1,RNN_HIDDEN_DIM), torch.zeros(1,1,RNN_HIDDEN_DIM))\n",
        "            output_char = torch.LongTensor([[self.alphabet[\"<start>\"]]]) # (1,1)\n",
        "            result = []\n",
        "            for _ in range(MAXWFLEN):\n",
        "                output_embedding = self.embedding(output_char) # (1,1,EMBEDDING_DIM)\n",
        "                emb = torch.cat([output_embedding, encoder_hs], dim = 2) # (1,1, embedding_dim + 2*rnn_hidden_dim)\n",
        "                hss, decoder_state = self.rnn(emb, decoder_state) \n",
        "                dist = self.hidden2char(decoder_state[0]).softmax(dim = 2) #(1,1,len(alphabet))\n",
        "                predicted_symbol = dist.argmax() # just a symbol\n",
        "                output_char = torch.LongTensor([[predicted_symbol]]) # (1,1)\n",
        "                result.append(output_char.numpy().tolist()[0][0])\n",
        "            return result\n",
        "            \n",
        "# Assertions to test that your implementation returns objects of the correct size. \n",
        "alphabet = vocab.get_stoi()\n",
        "encoder_hs = Encoder(alphabet)(example)\n",
        "_, output_length = example.output\n",
        "alphabet_size = len(alphabet)\n",
        "\n",
        "assert(Decoder(alphabet)(example,encoder_hs)[0].size() == torch.Size([output_length - 1,1,alphabet_size]))\n",
        "assert(len(Decoder(alphabet).generate(encoder_hs)) == MAXWFLEN)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-d-do2sG6f2A"
      },
      "source": [
        "#### Training the Model\n",
        "\n",
        "`WordInflector` class combines the encoder and decoder networks. \n",
        "\n",
        "<!-- We also give you some code for training a `WordInflector`. This code will run backpropagation through time using the Adam optimizer. -->\n",
        "\n",
        "<!-- Running 10 epochs of the training algorithm on the Spanish medium training set spanning 1,000 examples, you should come close to 10% accuracy. This is quite modest but it shows that your model is indeed training. If you are seeing 0-1% accuracy after training 10 epochs, then you have a problem somewhere in your code. -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KLJHrxS6f2A",
        "outputId": "22184bb6-2274-421d-83f1-e7db860772a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1000 of 1000\n",
            "EPOCH 1: AVG LOSS PER EX: 4.95871\n",
            "DEV ACC: 0.00%\n",
            "Example 1000 of 1000\n",
            "EPOCH 2: AVG LOSS PER EX: 3.69327\n",
            "DEV ACC: 0.00%\n",
            "Example 1000 of 1000\n",
            "EPOCH 3: AVG LOSS PER EX: 2.89394\n",
            "DEV ACC: 0.40%\n",
            "Example 1000 of 1000\n",
            "EPOCH 4: AVG LOSS PER EX: 2.33738\n",
            "DEV ACC: 1.20%\n",
            "Example 1000 of 1000\n",
            "EPOCH 5: AVG LOSS PER EX: 1.93215\n",
            "DEV ACC: 2.90%\n",
            "Example 1000 of 1000\n",
            "EPOCH 6: AVG LOSS PER EX: 1.62633\n",
            "DEV ACC: 4.00%\n",
            "Example 1000 of 1000\n",
            "EPOCH 7: AVG LOSS PER EX: 1.38394\n",
            "DEV ACC: 5.50%\n",
            "Example 1000 of 1000\n",
            "EPOCH 8: AVG LOSS PER EX: 1.17550\n",
            "DEV ACC: 7.50%\n",
            "Example 1000 of 1000\n",
            "EPOCH 9: AVG LOSS PER EX: 1.04067\n",
            "DEV ACC: 8.50%\n",
            "Example 1000 of 1000\n",
            "EPOCH 10: AVG LOSS PER EX: 0.87147\n",
            "DEV ACC: 10.10%\n"
          ]
        }
      ],
      "source": [
        "class WordInflector(nn.Module):\n",
        "    def __init__(self, alphabet):\n",
        "        super(WordInflector, self).__init__()\n",
        "        self.alphabet = alphabet.get_stoi()\n",
        "        self.integer2char = alphabet.get_itos()\n",
        "        alphabet_size = len(self.alphabet)\n",
        "        \n",
        "        self.encoder = Encoder(self.alphabet)\n",
        "        self.decoder = Decoder(self.alphabet)\n",
        "    \n",
        "    def get_string(self,ids):\n",
        "        string = ''.join([self.integer2char[i] for i in ids])\n",
        "        return re.sub(\"%s.*\" % \"<end>\",\"\",string)\n",
        "\n",
        "    def forward(self, example):\n",
        "        encoder_hs = self.encoder(example)\n",
        "        return self.decoder(example,encoder_hs)\n",
        "            \n",
        "    def generate(self, data):\n",
        "        all_results = []\n",
        "        with torch.no_grad():\n",
        "            for example in data:\n",
        "                encoder_hs = self.encoder(example)\n",
        "                output = self.decoder.generate(encoder_hs)\n",
        "                all_results.append(self.get_string(output))\n",
        "        return all_results\n",
        "    \n",
        "if __name__==\"__main__\":\n",
        "    # Read the Spanish medium data set.\n",
        "    train_iter, dev_iter, test_iter, vocab = read_data(language=\"spanish\",\n",
        "                                                       setting=\"medium\",\n",
        "                                                       batch_size=1)\n",
        "    \n",
        "    inflector = WordInflector(vocab)\n",
        "\n",
        "    loss_function = nn.NLLLoss(ignore_index=vocab[\"<pad>\"],reduction='mean')\n",
        "    optimizer = Adam(inflector.parameters())\n",
        "    gold_dev_words = [''.join(w.output) for w in dev_iter.dataset]\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        tot_loss = 0 \n",
        "\n",
        "        # Update parameters\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            print(\"Example %u of %u\" % (i+1,len(train_iter)),end=\"\\r\")\n",
        "            inflector.zero_grad()\n",
        "            tag_scores, tgt = inflector(batch)\n",
        "            tgt = tgt.permute(1,0)\n",
        "            tag_scores = tag_scores.permute(1,2,0)\n",
        "            loss = loss_function(tag_scores,tgt) \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            tot_loss += len(batch)*loss.detach().numpy()\n",
        "        print()\n",
        "        avg_loss = tot_loss/len(train_iter)\n",
        "        print(\"EPOCH %u: AVG LOSS PER EX: %.5f\" % (epoch+1,avg_loss))        \n",
        "\n",
        "        # Evaluate on dev data.\n",
        "        sys_dev_words = inflector.generate(dev_iter)\n",
        "        print(\"DEV ACC: %.2f%%\" % accuracy(sys_dev_words,gold_dev_words))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LOLyBU_-6f2A"
      },
      "source": [
        "### Encoder-Decoder with Attention\n",
        "\n",
        "\n",
        "The `forward` function for the old `Encoder` returned a single hidden state of dimension `(1,1,2*RNN_HIDDEN_DIM)`, namely the final hidden state. In contrast, you should return a hidden state for each time step, which means that `forward` should return a tensor of dimension `(input_length,1,2*RNN_HIDDEN_DIM)`. This will require a small change to your existing implementation of the `Encoder` class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NQuP8VZh6f2A"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "        def __init__(self,alphabet):\n",
        "                super(Encoder,self).__init__()\n",
        "                self.embedding = nn.Embedding(len(alphabet), EMBEDDING_DIM)\n",
        "                self.rnn = nn.LSTM(EMBEDDING_DIM, RNN_HIDDEN_DIM, RNN_LAYERS, bidirectional=True)\n",
        "\n",
        "        def forward(self,ex):\n",
        "            input, _ = ex.input #(sequence_len, 1)\n",
        "            input = self.embedding(input) # (sequence_len, 1, embedding_dim)\n",
        "            hss, (hn, cn) = self.rnn(input) # hss: (seq_len, 1, 2*rnn_hidden_dim)\n",
        "            return hss\n",
        "\n",
        "\n",
        "# An assertion to test that your implementation returns an object of the correct size. \n",
        "input, input_length = example.input\n",
        "assert(Encoder(vocab.get_stoi())(example).size() == torch.Size([input_length,1,2*RNN_HIDDEN_DIM]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "yyvLZQKT6f2B"
      },
      "source": [
        "The `Attention` class implements a version of [Bahdanau attention](https://blog.floydhub.com/attention-mechanism/). \n",
        "\n",
        "Its `forward` function takes two inputs: a tensor of encoder hidden states `encoder_hss` of dimension `(sequence_length, 1, 2*RNN_HIDDEN_DIM)` and a decoder hidden state `dec_state` of dimension `(1,1,RNN_HIDDEN_DIM)`. It computes a context weight for each of the encoder hidden states and the decoder hidden state using a feed-forward neural network with one hidden layer and a ReLU non-linearity. These weights are then normalized into a probability distribution $p_1, ..., p_T$ using a softmax layer. Finally, `forward` will return the weighted mean $p_1 e_1 + ... + p_T e_T$.      \n",
        "\n",
        "In order to implement the `forward` function, you should:\n",
        "\n",
        "1. Concatenate one copy of the decoder hidden state `decoder_hs` to each hidden state in `encoder_hss`. This will give you a tensor `conditioned` of dimension `(sequence_length,1,3*RNN_HIDDEN_DIM)`.\n",
        "1. Apply the first layer of the feed-forward network `self.attention1` and `self.relu` to `conditioned`. This should give you a tensor `att1` of dimension `()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5D0nKPOF6f2B"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention,self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(3*RNN_HIDDEN_DIM,RNN_HIDDEN_DIM)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(RNN_HIDDEN_DIM,1)\n",
        "    \n",
        "    def forward(self,encoder_hss,decoder_hs):\n",
        "        # encoder_hss : (seq_len, 1, 2*rnn_hidden_dim)\n",
        "        # decoder_hs: (1,1,rnn_hidden_dim)\n",
        "        decoder_hs_copy = decoder_hs.expand(encoder_hss.size()[0],-1,-1) # (seq_len, 1, rnn_hidden_dim)\n",
        "        concat = torch.cat([encoder_hss,decoder_hs_copy],dim=2) # (seq_len, 1, 3*rnn_hidden_dim)\n",
        "        att1 = self.linear1(concat)# (seq_len, 1, rnn_hidden_dim)\n",
        "        att1 = self.relu(att1) # (seq_len, 1, rnn_hidden_dim)\n",
        "        att1 = self.linear2(att1) # (seq_len, 1, 1)\n",
        "        # expand att1 to encoder_hss shape\n",
        "        att1 = att1.expand(-1,-1,2*RNN_HIDDEN_DIM) # (seq_len, 1, 2*rnn_hidden_dim)\n",
        "        mean_att_weight = torch.sum(att1*encoder_hss, dim=0) # (1, 2*rnn_hidden_dim)\n",
        "        context = mean_att_weight.unsqueeze(0) # (1, 1, 2*rnn_hidden_dim)\n",
        "        return context\n",
        "\n",
        "# An assertion to test that your implementation returns an object of the correct size. \n",
        "input, input_length = example.input\n",
        "encoder_hss = Encoder(vocab.get_stoi())(example)\n",
        "decoder_hs = torch.randn(1,1,RNN_HIDDEN_DIM)\n",
        "\n",
        "assert(Attention()(encoder_hss,decoder_hs).size() == torch.Size([1,1,2*RNN_HIDDEN_DIM]))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jLS_X1sb6f2B"
      },
      "source": [
        "The `Decoder` class will require some changes compared to the case without attention. The most drastic change concerns the `forward` function which will now become almost identical to the `generate` function.\n",
        "\n",
        "##### `Decoder.forward`\n",
        "\n",
        "The `forward` function takes a sequence of encoder hidden states given as a tensor `encoder_hss` corresponding to an input sequence like `<start> s t o d g e FEAT=V FEAT=PST <end>`. It has dimension `(sequence_length,1,2*RNN_HIDDEN_DIM)`. The `forward` function returns a tensor corresponding to the output sequence `s t o d g e d <end>`. As in the non-attentional case, the `forward` function does not directly return the output sequence. Instead, it returns a tensor `distr` of size `(output_length,1,alphabet_size)`. For example, `distr[6,0,15]` indicates the log-probability that the output symbol at position `t` will be symbol number `15` (imagine for example that `15 == self.alphabet[\"d\"]`).\n",
        "\n",
        "At each time-step `t`, the decoder uses `self.attention` to compute a context vector based on all of the encoder hidden states and the decoder hidden state `decoder_state` at time-step `t-1`. In contrast, to the `Decoder` without attention, we therefore need to recursively generate the output because the context vector depends on the decoder hidden state at time-step `t-1`. It is your task to maintain the internal state `decoder_state`. It is a pair `(hs,cs)`, where `hs` is the decoder hidden state and `cs` is its cell state.\n",
        "\n",
        "Since our decoder is trained using teacher forcing, we will feed in the gold standard output symbol at position `t-1` when predicting the output at position `t` in `forward`. You can access the gold standard output sequence via `ex.output`.\n",
        "\n",
        "In order to implement `forward`, you should:\n",
        "\n",
        "1. Embed the gold standard output word form in `ex.output` using `self.embedding`. This should give you a tensor `embedded_output` of size `(output_length - 1,1,EMBEDDING_DIM)` (note the `- 1` which is a result of clipping the `<end>` symbol form the output sequence `<start> s t o d g e d <end>`).\n",
        "1. Loop over the output sequence `<start> s t o d g e d <end>`.\n",
        "1. Use `self.attention` to compute a context vector based on the decoder hidden state and all encoder hidden states. This should give you a tensor `context` of dimension `(1,1,2*RNN_HIDDEN_DIM)`.\n",
        "1. Run `self.rnn` on the concatenation of `output_embedding` and `context`. Note that you need to initialize the decoder to `decoder_state`. You should use the return value to update `decoder_state`.\n",
        "1. Use the decoder hidden state `hs` from `decoder_state` and self.hidden2char to predict the distribution for the next output character and append it to the `result` array.  \n",
        "1. After `output_length - 1` time-steps, transform `result` into a tensor of dimension `(output_length - 1, 1, alphabet_size)` and return it (you should be able to transform the array into a tensor using `torch.cat`).\n",
        "\n",
        "##### `Decoder.generate`\n",
        "\n",
        "The `generate` function is very similar to the `forward` function except that we are not using teacher forcing.\n",
        "\n",
        "It takes only one argument: a sequence of encoder hidden states of dimension `(sequence_length,1,2*RNN_HIDDEN_STATE)`. In contrast to `forward`, you don't get a gold standard output sequence as parameter since we need to use `generate` during test time. Instead, it is your task to recursively generate the output sequence starting with the sequence inital symbol `<start>`. \n",
        "\n",
        "At each time step, you should compute a `context` vector using `self.attention`, the current decoder state `decoder_state` and the sequence of encoder hidden states `encoder_hss`. You should then feed the current output symbol `output_char` and the context vector `context` as input to the decoder. \n",
        "\n",
        "It is your task to maintain the internal state `decoder_state`. It is a pair `(hs,cs)`, where `hs` is the decoder hidden state and `cs` is its cell state. You need to initialize the decoder to this state and update it using the return value of `self.rnn.forward`. You should then predict the next output symbol using the updated value of `decoder_state` and `self.hidden2char` echoing the `forward` function you just implemented.\n",
        "\n",
        "The `generate` function always produces an output of length `MAXWFLEN` but since this output may contain the `<end>` symbol, we can in reality generate shorter output sequences because `a b c <end> <end> ...` corresponds to the output word form `a b c`.\n",
        "\n",
        "In order to implement `generate`, you should:\n",
        "\n",
        "1. Embed `output_char` using `self.embedding`. This should give you a tensor `output_embedding` of dimension `(1,1,EMBEDDING_DIM)`.\n",
        "1. Compute a `context` vector using `self.attention`. You need to give `decoder_state` and `encoder_hss` as input to `self.attention`. This should result in `context` tensor of dimension `(1,1,2*RNN_HIDDEN_DIM)`.\n",
        "1. Run `self.rnn` on the concatenation of `output_embedding` and `context`. Note that you need to initialize the decoder to `decoder_state`. You should use the return value to update `decoder_state`.\n",
        "1. Use the decoder hidden state `hs` from `decoder_state` and self.hidden2char to predict the next output character. You will probably need to use torch.argmax to find the most probable output symbol.\n",
        "1. Update the value of the `output_char` variable to the current output character and add it to the result array. Note that if `output_char == torch.Tensor([[1]])`, then you need to add the integer `1` to result. \n",
        "1. After `MAXWFLEN` time-steps, return `result`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[tensor([[ 1.0266, -0.8604,  0.7567],\n",
            "        [-0.3657, -2.0474, -0.4515]]), tensor([[ 0.2081, -0.6706,  0.8777],\n",
            "        [ 0.0225,  0.3548,  0.3639]])]\n",
            "tensor([[ 1.0266, -0.8604,  0.7567],\n",
            "        [-0.3657, -2.0474, -0.4515],\n",
            "        [ 0.2081, -0.6706,  0.8777],\n",
            "        [ 0.0225,  0.3548,  0.3639]])\n",
            "torch.Size([4, 3])\n"
          ]
        }
      ],
      "source": [
        "x = [torch.randn(2, 3),torch.randn(2, 3)] #(2,2,3)\n",
        "print(x)\n",
        "y = torch.cat(x,dim=0)\n",
        "print(y)\n",
        "print(y.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jh6Wr9oU6f2B"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, alphabet):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.alphabet = alphabet\n",
        "        self.embedding = nn.Embedding(len(alphabet), EMBEDDING_DIM)\n",
        "        self.attention = Attention()\n",
        "        self.rnn = nn.LSTM(EMBEDDING_DIM+2*RNN_HIDDEN_DIM, RNN_HIDDEN_DIM, RNN_LAYERS, bidirectional=False)\n",
        "        self.hidden2char = nn.Linear(RNN_HIDDEN_DIM, len(alphabet))\n",
        "    \n",
        "    def forward(self,ex,encoder_hss):\n",
        "        output, output_length = ex.output\n",
        "        embedded_output = self.embedding(output[:-1]) # clip <end> (output_len -1, 1, embedding_dim)\n",
        "        results = []\n",
        "        decoder_state = (torch.zeros(1,1,RNN_HIDDEN_DIM,requires_grad=False), \n",
        "                         torch.zeros(1,1,RNN_HIDDEN_DIM,requires_grad=False)) # initialize zero decoder states (hs, cs)\n",
        "        for i in range(output_length-1):\n",
        "            context = self.attention(encoder_hss, decoder_state[0]) #(1,1,2*rnn_hidden_dim)\n",
        "            output_i = embedded_output[i].unsqueeze(0) # (1,1, embedding_dim)\n",
        "            decoder_input = torch.cat([output_i,context], dim=2) # (1,1, embedding_dim+2*rnn_hidden_dim)\n",
        "            hss,(hs, cs) = self.rnn(decoder_input,decoder_state) # hs:(1,1, rnn_hidden_dim)\n",
        "            decoder_state = (hs, cs)\n",
        "            dist = self.hidden2char(hs) # hs:(1,1, len(vocab))\n",
        "            results.append(dist)\n",
        "        \n",
        "        # results : (output_len-1, 1, 1, len(vocab))\n",
        "        results = torch.cat(results, dim=0) # results : (output_len-1,1, len(vocab))\n",
        "        return results.log_softmax(dim=2), output[1:] # (output_len-1,1, len(alphabet_size))\n",
        "\n",
        "        \n",
        "    def generate(self,encoder_hss):\n",
        "        with torch.no_grad():\n",
        "            decoder_state = (torch.zeros(1,1,RNN_HIDDEN_DIM), torch.zeros(1,1,RNN_HIDDEN_DIM))\n",
        "            output_char = torch.LongTensor([[self.alphabet[\"<start>\"]]]) # (1,1)\n",
        "            result = []\n",
        "            for _ in range(MAXWFLEN):\n",
        "                output_embedding = self.embedding(output_char) # (1,1,EMBEDDING_DIM)\n",
        "                context = self.attention(encoder_hss, decoder_state[0]) #(1,1,2*rnn_hidden_dim)\n",
        "                decoder_input = torch.cat([output_embedding,context], dim=2) # (1,1, embedding_dim+2*rnn_hidden_dim)\n",
        "                hss, (hs, cs) = self.rnn(decoder_input,decoder_state)  # hs:(1,1, rnn_hidden_dim)\n",
        "                decoder_state = (hs, cs)\n",
        "                dist = self.hidden2char(hs).softmax(dim=2) #(1,1,len(alphabet))\n",
        "                predicted_symbol = dist.argmax() # just a symbol\n",
        "                output_char = torch.LongTensor([[predicted_symbol]]) # (1,1)\n",
        "                result.append(output_char.numpy().tolist()[0][0])\n",
        "            return result\n",
        "            \n",
        "# Assertions to test that your implementation returns objects of the correct size. \n",
        "encoder_hs = Encoder(vocab.get_stoi())(example)\n",
        "_, output_length = example.output\n",
        "alphabet = vocab.get_stoi()\n",
        "alphabet_size = len(alphabet)\n",
        "assert(Decoder(alphabet)(example,encoder_hs)[0].size() == torch.Size([output_length - 1,1,alphabet_size]))\n",
        "assert(len(Decoder(alphabet).generate(encoder_hs)) == MAXWFLEN)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4K8pfRq_6f2C"
      },
      "source": [
        "#### Training the Model\n",
        "\n",
        "provided code for a `WordInflector` class which combines the encoder and decoder networks.\n",
        "\n",
        "Running 10 epochs of the training algorithm on the Spanish medium training set spanning 1,000 examples, you should get development accuracy > 50%. If you are seeing < 20% accuracy after training 10 epochs, then you have a problem somewhere in your code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "TdoR7ADy6f2C",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example 1000 of 1000\n",
            "EPOCH 1: AVG LOSS PER EX: 2.54354\n",
            "DEV ACC: 0.00%\n",
            "Example 1000 of 1000\n",
            "EPOCH 2: AVG LOSS PER EX: 1.65693\n",
            "DEV ACC: 1.00%\n",
            "Example 1000 of 1000\n",
            "EPOCH 3: AVG LOSS PER EX: 1.05424\n",
            "DEV ACC: 8.50%\n",
            "Example 1000 of 1000\n",
            "EPOCH 4: AVG LOSS PER EX: 0.69113\n",
            "DEV ACC: 22.90%\n",
            "Example 1000 of 1000\n",
            "EPOCH 5: AVG LOSS PER EX: 0.47361\n",
            "DEV ACC: 35.50%\n",
            "Example 1000 of 1000\n",
            "EPOCH 6: AVG LOSS PER EX: 0.33736\n",
            "DEV ACC: 41.60%\n",
            "Example 1000 of 1000\n",
            "EPOCH 7: AVG LOSS PER EX: 0.27975\n",
            "DEV ACC: 48.40%\n",
            "Example 1000 of 1000\n",
            "EPOCH 8: AVG LOSS PER EX: 0.21874\n",
            "DEV ACC: 21.70%\n",
            "Example 1000 of 1000\n",
            "EPOCH 9: AVG LOSS PER EX: 0.20619\n",
            "DEV ACC: 58.40%\n",
            "Example 1000 of 1000\n",
            "EPOCH 10: AVG LOSS PER EX: 0.15511\n",
            "DEV ACC: 62.20%\n"
          ]
        }
      ],
      "source": [
        "class WordInflector(nn.Module):\n",
        "    def __init__(self, alphabet):\n",
        "        super(WordInflector, self).__init__()\n",
        "        self.c2i = alphabet.get_stoi()\n",
        "        self.i2c = alphabet.get_itos()\n",
        "        alphabet_size = len(self.c2i)\n",
        "        \n",
        "        self.encoder = Encoder(self.c2i)\n",
        "        self.decoder = Decoder(self.c2i)\n",
        "    \n",
        "    def get_string(self,ids):\n",
        "        string = ''.join([self.i2c[i] for i in ids])\n",
        "        return re.sub(\"%s.*\" % \"<end>\",\"\",string)\n",
        "\n",
        "    def forward(self, example):\n",
        "        encoder_hs = self.encoder(example)\n",
        "        return self.decoder(example,encoder_hs)\n",
        "            \n",
        "    def generate(self, data):\n",
        "        all_results = []\n",
        "        with torch.no_grad():\n",
        "            for example in data:\n",
        "                encoder_hs = self.encoder(example)\n",
        "                output = self.decoder.generate(encoder_hs)\n",
        "                all_results.append(self.get_string(output))\n",
        "        return all_results\n",
        "    \n",
        "if __name__==\"__main__\":\n",
        "    train_iter, dev_iter, test_iter, vocab = read_data(language=\"spanish\",\n",
        "                                                       setting=\"medium\",\n",
        "                                                       batch_size=1)\n",
        "    \n",
        "    inflector = WordInflector(vocab)\n",
        "\n",
        "    loss_function = nn.NLLLoss(ignore_index=inflector.c2i[\"<pad>\"],reduction='mean')\n",
        "    optimizer = Adam(inflector.parameters())\n",
        "    gold_dev_words = [''.join(w.output) for w in dev_iter.dataset]\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        tot_loss = 0 \n",
        "\n",
        "        # Update parameters\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            print(\"Example %u of %u\" % (i+1,len(train_iter)),end=\"\\r\")\n",
        "            inflector.zero_grad()\n",
        "            tag_scores, tgt = inflector(batch)\n",
        "            tgt = tgt.permute(1,0)\n",
        "            tag_scores = tag_scores.permute(1,2,0)\n",
        "            loss = loss_function(tag_scores,tgt) \n",
        "            tot_loss += loss.detach().numpy()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        print()\n",
        "        avg_loss = tot_loss/len(train_iter)\n",
        "        print(\"EPOCH %u: AVG LOSS PER EX: %.5f\" % (epoch+1,avg_loss))        \n",
        "\n",
        "        # Evaluate on dev data.\n",
        "        sys_dev_words = inflector.generate(dev_iter)\n",
        "        print(\"DEV ACC: %.2f%%\" % accuracy(sys_dev_words,gold_dev_words))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
